# Training hyperparameters for DistilGPT-2 (Quick test configuration)
defaults:
  - _self_

batch_size: 8
lr: 2e-5
max_epochs: 3
eval_steps: 200
max_samples: null

wandb:
  project: "my_medical_lm"
  entity: null  # your wandb username/org
  gcp_project_id: "hardy-abode-316815"
  secret_id: "WANDB_API_KEY"
